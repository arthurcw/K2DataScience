{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "# Predictive Modeling from Lending Club\n",
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lending club currently gives a loan a grade and sub-grade. Each grade has a range of interest level associated with it. Are these grades predictive of default (classification) or the remaining outstanding principal for portion of total amount funded by investors (regression) if a loan does default? Can we make a better model of whether or not a loanee will default? Furthermore, if a loanee does default can we predict how much the investors will be out? If there is a high probability that a loanee defaults, investors may still make a profit with a high enough interest rate. Our job is to model creditworthiness by predicting who will default and model good vs. bad investments by predicting the amount investors will be out.\n",
    "\n",
    "The first step here is to perform an EDA on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1 Data Import\n",
    "    * 1.1 Missing Columns\n",
    "    * 1.2 Missing Data \n",
    "* 2 Feature Transformation & Engineering\n",
    "    * 2.1 emp_length\n",
    "    * 2.2 term\n",
    "    * 2.3 categorical datatypes\n",
    "        * 2.3.1 categorical columns - keep\n",
    "        * 2.3.2 categorical columns - drop\n",
    "    * 2.4 date columns\n",
    "        * 2.4.1 date columns - keep\n",
    "        * 2.4.2. date columns - drop \n",
    "    * 2.5 loan status\n",
    "    * 2.6 issue_d\n",
    "    * 2.7 inq_last_6mths\n",
    "    * 2.8 pub_rec\n",
    "    * 2.9 funded_amnt\n",
    "* 3 Data Exploration\n",
    "    * 3.1 loan amount\n",
    "    * 3.2 default vs non-default loans\n",
    "    * 3.3 issue date\n",
    "    * 3.4 terms\n",
    "    * 3.5 grade\n",
    "    * 3.6 interest rates\n",
    "    * 3.7 home ownership\n",
    "    * 3.8 purpose\n",
    "    * 3.9 state\n",
    "* 4 Correlation\n",
    "* 5 Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', color_codes=True)\n",
    "#plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import our lending club data\n",
    "#\n",
    "# Note: I'm using the 'low_memory=False' flag to silence a memory warning.  We could specify \n",
    "# the dtypes of columns to lower the memory consumption.  The provided csv file is\n",
    "# not too large, so I am fine with simply silencing the error in this particular case. \n",
    "\n",
    "# create the path to the data\n",
    "path = '../data/raw/'\n",
    "\n",
    "# list our file names\n",
    "loan_stat_files = ['LoanStats3a.csv',\n",
    "             'LoanStats3b.csv',\n",
    "             'LoanStats3c.csv',\n",
    "             'LoanStats3d.csv',\n",
    "             'LoanStats_2016Q1.csv',\n",
    "             'LoanStats_2016Q2.csv',\n",
    "             'LoanStats_2016Q3.csv',\n",
    "             'LoanStats_2016Q4.csv',\n",
    "             'LoanStats_2017Q1.csv',\n",
    "             'LoanStats_2017Q2.csv',\n",
    "             'LoanStats_2017Q3.csv'\n",
    "            ]\n",
    "\n",
    "dfs=[]\n",
    "for f in loan_stat_files:\n",
    "    df_temp = pd.read_csv(os.path.join(path, f), low_memory=False)\n",
    "    dfs.append(df_temp)\n",
    "\n",
    "df = pd.concat(dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 697532 entries, 0 to 65498\n",
      "Data columns (total 144 columns):\n",
      "member_id                                     0 non-null float64\n",
      "loan_amnt                                     697525 non-null float64\n",
      "funded_amnt                                   697525 non-null float64\n",
      "funded_amnt_inv                               697525 non-null float64\n",
      "term                                          697525 non-null object\n",
      "int_rate                                      697525 non-null object\n",
      "installment                                   697525 non-null float64\n",
      "grade                                         697525 non-null object\n",
      "sub_grade                                     697525 non-null object\n",
      "emp_title                                     652154 non-null object\n",
      "emp_length                                    655261 non-null object\n",
      "home_ownership                                697525 non-null object\n",
      "annual_inc                                    697521 non-null float64\n",
      "verification_status                           697525 non-null object\n",
      "issue_d                                       697525 non-null object\n",
      "loan_status                                   697525 non-null object\n",
      "pymnt_plan                                    697525 non-null object\n",
      "url                                           0 non-null float64\n",
      "desc                                          49540 non-null object\n",
      "purpose                                       697525 non-null object\n",
      "title                                         684127 non-null object\n",
      "zip_code                                      697525 non-null object\n",
      "addr_state                                    697525 non-null object\n",
      "dti                                           697286 non-null float64\n",
      "delinq_2yrs                                   697496 non-null float64\n",
      "earliest_cr_line                              697496 non-null object\n",
      "inq_last_6mths                                697496 non-null float64\n",
      "mths_since_last_delinq                        352404 non-null float64\n",
      "mths_since_last_record                        120066 non-null float64\n",
      "open_acc                                      697496 non-null float64\n",
      "pub_rec                                       697496 non-null float64\n",
      "revol_bal                                     697525 non-null float64\n",
      "revol_util                                    696997 non-null object\n",
      "total_acc                                     697496 non-null float64\n",
      "initial_list_status                           697525 non-null object\n",
      "out_prncp                                     697525 non-null float64\n",
      "out_prncp_inv                                 697525 non-null float64\n",
      "total_pymnt                                   697525 non-null float64\n",
      "total_pymnt_inv                               697525 non-null float64\n",
      "total_rec_prncp                               697525 non-null float64\n",
      "total_rec_int                                 697525 non-null float64\n",
      "total_rec_late_fee                            697525 non-null float64\n",
      "recoveries                                    697525 non-null float64\n",
      "collection_recovery_fee                       697525 non-null float64\n",
      "last_pymnt_d                                  690203 non-null object\n",
      "last_pymnt_amnt                               697525 non-null float64\n",
      "next_pymnt_d                                  446336 non-null object\n",
      "last_credit_pull_d                            697483 non-null object\n",
      "collections_12_mths_ex_med                    697380 non-null float64\n",
      "mths_since_last_major_derog                   181551 non-null float64\n",
      "policy_code                                   697525 non-null float64\n",
      "application_type                              697525 non-null object\n",
      "annual_inc_joint                              22098 non-null float64\n",
      "dti_joint                                     22095 non-null float64\n",
      "verification_status_joint                     22098 non-null object\n",
      "acc_now_delinq                                697496 non-null float64\n",
      "tot_coll_amt                                  654990 non-null float64\n",
      "tot_cur_bal                                   654990 non-null float64\n",
      "open_acc_6m                                   479865 non-null float64\n",
      "open_act_il                                   479865 non-null float64\n",
      "open_il_12m                                   479865 non-null float64\n",
      "open_il_24m                                   479865 non-null float64\n",
      "mths_since_rcnt_il                            466590 non-null float64\n",
      "total_bal_il                                  479865 non-null float64\n",
      "il_util                                       415715 non-null float64\n",
      "open_rv_12m                                   479865 non-null float64\n",
      "open_rv_24m                                   479865 non-null float64\n",
      "max_bal_bc                                    479865 non-null float64\n",
      "all_util                                      479833 non-null float64\n",
      "total_rev_hi_lim                              654990 non-null float64\n",
      "inq_fi                                        479865 non-null float64\n",
      "total_cu_tl                                   479865 non-null float64\n",
      "inq_last_12m                                  479865 non-null float64\n",
      "acc_open_past_24mths                          654990 non-null float64\n",
      "avg_cur_bal                                   654984 non-null float64\n",
      "bc_open_to_buy                                647709 non-null float64\n",
      "bc_util                                       647387 non-null float64\n",
      "chargeoff_within_12_mths                      697380 non-null float64\n",
      "delinq_amnt                                   697496 non-null float64\n",
      "mo_sin_old_il_acct                            636247 non-null float64\n",
      "mo_sin_old_rev_tl_op                          654990 non-null float64\n",
      "mo_sin_rcnt_rev_tl_op                         654990 non-null float64\n",
      "mo_sin_rcnt_tl                                654990 non-null float64\n",
      "mort_acc                                      654990 non-null float64\n",
      "mths_since_recent_bc                          648153 non-null float64\n",
      "mths_since_recent_bc_dlq                      163758 non-null float64\n",
      "mths_since_recent_inq                         584616 non-null float64\n",
      "mths_since_recent_revol_delinq                231759 non-null float64\n",
      "num_accts_ever_120_pd                         654990 non-null float64\n",
      "num_actv_bc_tl                                654990 non-null float64\n",
      "num_actv_rev_tl                               654990 non-null float64\n",
      "num_bc_sats                                   654990 non-null float64\n",
      "num_bc_tl                                     654990 non-null float64\n",
      "num_il_tl                                     654990 non-null float64\n",
      "num_op_rev_tl                                 654990 non-null float64\n",
      "num_rev_accts                                 654990 non-null float64\n",
      "num_rev_tl_bal_gt_0                           654990 non-null float64\n",
      "num_sats                                      654990 non-null float64\n",
      "num_tl_120dpd_2m                              627583 non-null float64\n",
      "num_tl_30dpd                                  654990 non-null float64\n",
      "num_tl_90g_dpd_24m                            654990 non-null float64\n",
      "num_tl_op_past_12m                            654990 non-null float64\n",
      "pct_tl_nvr_dlq                                654837 non-null float64\n",
      "percent_bc_gt_75                              647618 non-null float64\n",
      "pub_rec_bankruptcies                          696160 non-null float64\n",
      "tax_liens                                     697420 non-null float64\n",
      "tot_hi_cred_lim                               654990 non-null float64\n",
      "total_bal_ex_mort                             654990 non-null float64\n",
      "total_bc_limit                                654990 non-null float64\n",
      "total_il_high_credit_limit                    654990 non-null float64\n",
      "revol_bal_joint                               14120 non-null float64\n",
      "sec_app_earliest_cr_line                      14120 non-null object\n",
      "sec_app_inq_last_6mths                        14120 non-null float64\n",
      "sec_app_mort_acc                              14120 non-null float64\n",
      "sec_app_open_acc                              14120 non-null float64\n",
      "sec_app_revol_util                            13926 non-null float64\n",
      "sec_app_open_act_il                           14120 non-null float64\n",
      "sec_app_num_rev_accts                         14120 non-null float64\n",
      "sec_app_chargeoff_within_12_mths              14120 non-null float64\n",
      "sec_app_collections_12_mths_ex_med            14120 non-null float64\n",
      "sec_app_mths_since_last_major_derog           4916 non-null float64\n",
      "hardship_flag                                 697525 non-null object\n",
      "hardship_type                                 2255 non-null object\n",
      "hardship_reason                               2255 non-null object\n",
      "hardship_status                               2255 non-null object\n",
      "deferral_term                                 2255 non-null float64\n",
      "hardship_amount                               2255 non-null float64\n",
      "hardship_start_date                           2255 non-null object\n",
      "hardship_end_date                             2255 non-null object\n",
      "payment_plan_start_date                       2255 non-null object\n",
      "hardship_length                               2255 non-null float64\n",
      "hardship_dpd                                  2255 non-null float64\n",
      "hardship_loan_status                          2255 non-null object\n",
      "orig_projected_additional_accrued_interest    2010 non-null float64\n",
      "hardship_payoff_balance_amount                2255 non-null float64\n",
      "hardship_last_payment_amount                  2255 non-null float64\n",
      "disbursement_method                           697525 non-null object\n",
      "debt_settlement_flag                          697525 non-null object\n",
      "debt_settlement_flag_date                     3192 non-null object\n",
      "settlement_status                             3192 non-null object\n",
      "settlement_date                               3192 non-null object\n",
      "settlement_amount                             3192 non-null float64\n",
      "settlement_percentage                         3192 non-null float64\n",
      "settlement_term                               3192 non-null float64\n",
      "dtypes: float64(106), object(38)\n",
      "memory usage: 771.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True,null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Missing Columns\n",
    "Lending club has provided us with an Excel file containing an explanation of each column.  It appears that the number columns in the Excel file differs from the data provided in our CSV.  Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data from excel file (which explains all column types)\n",
    "excel_desc = pd.read_excel('../data/raw/LCDataDictionary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LoanStatNew</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acc_now_delinq</td>\n",
       "      <td>The number of accounts on which the borrower i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acc_open_past_24mths</td>\n",
       "      <td>Number of trades opened in past 24 months.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>addr_state</td>\n",
       "      <td>The state provided by the borrower in the loan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>all_util</td>\n",
       "      <td>Balance to credit limit on all trades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annual_inc</td>\n",
       "      <td>The self-reported annual income provided by th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>annual_inc_joint</td>\n",
       "      <td>The combined self-reported annual income provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>application_type</td>\n",
       "      <td>Indicates whether the loan is an individual ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avg_cur_bal</td>\n",
       "      <td>Average current balance of all accounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bc_open_to_buy</td>\n",
       "      <td>Total open to buy on revolving bankcards.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bc_util</td>\n",
       "      <td>Ratio of total current balance to high credit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chargeoff_within_12_mths</td>\n",
       "      <td>Number of charge-offs within 12 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>collection_recovery_fee</td>\n",
       "      <td>post charge off collection fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>collections_12_mths_ex_med</td>\n",
       "      <td>Number of collections in 12 months excluding m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>delinq_2yrs</td>\n",
       "      <td>The number of 30+ days past-due incidences of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>delinq_amnt</td>\n",
       "      <td>The past-due amount owed for the accounts on w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>desc</td>\n",
       "      <td>Loan description provided by the borrower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dti</td>\n",
       "      <td>A ratio calculated using the borrower’s total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dti_joint</td>\n",
       "      <td>A ratio calculated using the co-borrowers' tot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>earliest_cr_line</td>\n",
       "      <td>The month the borrower's earliest reported cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>emp_length</td>\n",
       "      <td>Employment length in years. Possible values ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>emp_title</td>\n",
       "      <td>The job title supplied by the Borrower when ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>fico_range_high</td>\n",
       "      <td>The upper boundary range the borrower’s FICO a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fico_range_low</td>\n",
       "      <td>The lower boundary range the borrower’s FICO a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>funded_amnt</td>\n",
       "      <td>The total amount committed to that loan at tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>funded_amnt_inv</td>\n",
       "      <td>The total amount committed by investors for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>grade</td>\n",
       "      <td>LC assigned loan grade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>home_ownership</td>\n",
       "      <td>The home ownership status provided by the borr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id</td>\n",
       "      <td>A unique LC assigned ID for the loan listing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>il_util</td>\n",
       "      <td>Ratio of total current balance to high credit/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>initial_list_status</td>\n",
       "      <td>The initial listing status of the loan. Possib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sec_app_open_act_il</td>\n",
       "      <td>Number of currently active installment trades...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sec_app_num_rev_accts</td>\n",
       "      <td>Number of revolving accounts at time of appli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sec_app_chargeoff_within_12_mths</td>\n",
       "      <td>Number of charge-offs within last 12 months a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sec_app_collections_12_mths_ex_med</td>\n",
       "      <td>Number of collections within last 12 months e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sec_app_mths_since_last_major_derog</td>\n",
       "      <td>Months since most recent 90-day or worse rati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>hardship_flag</td>\n",
       "      <td>Flags whether or not the borrower is on a hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>hardship_type</td>\n",
       "      <td>Describes the hardship plan offering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>hardship_reason</td>\n",
       "      <td>Describes the reason the hardship plan was off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>hardship_status</td>\n",
       "      <td>Describes if the hardship plan is active, pend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>deferral_term</td>\n",
       "      <td>Amount of months that the borrower is expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>hardship_amount</td>\n",
       "      <td>The interest payment that the borrower has com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>hardship_start_date</td>\n",
       "      <td>The start date of the hardship plan period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>hardship_end_date</td>\n",
       "      <td>The end date of the hardship plan period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>payment_plan_start_date</td>\n",
       "      <td>The day the first hardship plan payment is due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>hardship_length</td>\n",
       "      <td>The number of months the borrower will make sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>hardship_dpd</td>\n",
       "      <td>Account days past due as of the hardship plan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>hardship_loan_status</td>\n",
       "      <td>Loan Status as of the hardship plan start date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>orig_projected_additional_accrued_interest</td>\n",
       "      <td>The original projected additional interest amo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>hardship_payoff_balance_amount</td>\n",
       "      <td>The payoff balance amount as of the hardship p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>hardship_last_payment_amount</td>\n",
       "      <td>The last payment amount as of the hardship pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>disbursement_method</td>\n",
       "      <td>The method by which the borrower receives thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>debt_settlement_flag</td>\n",
       "      <td>Flags whether or not the borrower, who has cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>debt_settlement_flag_date</td>\n",
       "      <td>The most recent date that the Debt_Settlement_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>settlement_status</td>\n",
       "      <td>The status of the borrower’s settlement plan. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>settlement_date</td>\n",
       "      <td>The date that the borrower agrees to the settl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>settlement_amount</td>\n",
       "      <td>The loan amount that the borrower has agreed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>settlement_percentage</td>\n",
       "      <td>The settlement amount as a percentage of the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>settlement_term</td>\n",
       "      <td>The number of months that the borrower will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>* Employer Title replaces Employer Name for al...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    LoanStatNew  \\\n",
       "0                                acc_now_delinq   \n",
       "1                          acc_open_past_24mths   \n",
       "2                                    addr_state   \n",
       "3                                      all_util   \n",
       "4                                    annual_inc   \n",
       "5                              annual_inc_joint   \n",
       "6                              application_type   \n",
       "7                                   avg_cur_bal   \n",
       "8                                bc_open_to_buy   \n",
       "9                                       bc_util   \n",
       "10                     chargeoff_within_12_mths   \n",
       "11                      collection_recovery_fee   \n",
       "12                   collections_12_mths_ex_med   \n",
       "13                                  delinq_2yrs   \n",
       "14                                  delinq_amnt   \n",
       "15                                         desc   \n",
       "16                                          dti   \n",
       "17                                    dti_joint   \n",
       "18                             earliest_cr_line   \n",
       "19                                   emp_length   \n",
       "20                                    emp_title   \n",
       "21                              fico_range_high   \n",
       "22                               fico_range_low   \n",
       "23                                  funded_amnt   \n",
       "24                              funded_amnt_inv   \n",
       "25                                        grade   \n",
       "26                               home_ownership   \n",
       "27                                           id   \n",
       "28                                      il_util   \n",
       "29                          initial_list_status   \n",
       "..                                          ...   \n",
       "123                         sec_app_open_act_il   \n",
       "124                      sec_app_num_rev_accts    \n",
       "125           sec_app_chargeoff_within_12_mths    \n",
       "126         sec_app_collections_12_mths_ex_med    \n",
       "127        sec_app_mths_since_last_major_derog    \n",
       "128                               hardship_flag   \n",
       "129                               hardship_type   \n",
       "130                             hardship_reason   \n",
       "131                             hardship_status   \n",
       "132                               deferral_term   \n",
       "133                             hardship_amount   \n",
       "134                         hardship_start_date   \n",
       "135                           hardship_end_date   \n",
       "136                     payment_plan_start_date   \n",
       "137                             hardship_length   \n",
       "138                                hardship_dpd   \n",
       "139                        hardship_loan_status   \n",
       "140  orig_projected_additional_accrued_interest   \n",
       "141              hardship_payoff_balance_amount   \n",
       "142                hardship_last_payment_amount   \n",
       "143                         disbursement_method   \n",
       "144                        debt_settlement_flag   \n",
       "145                   debt_settlement_flag_date   \n",
       "146                           settlement_status   \n",
       "147                             settlement_date   \n",
       "148                           settlement_amount   \n",
       "149                       settlement_percentage   \n",
       "150                             settlement_term   \n",
       "151                                         NaN   \n",
       "152                                         NaN   \n",
       "\n",
       "                                           Description  \n",
       "0    The number of accounts on which the borrower i...  \n",
       "1           Number of trades opened in past 24 months.  \n",
       "2    The state provided by the borrower in the loan...  \n",
       "3                Balance to credit limit on all trades  \n",
       "4    The self-reported annual income provided by th...  \n",
       "5    The combined self-reported annual income provi...  \n",
       "6    Indicates whether the loan is an individual ap...  \n",
       "7              Average current balance of all accounts  \n",
       "8            Total open to buy on revolving bankcards.  \n",
       "9    Ratio of total current balance to high credit/...  \n",
       "10              Number of charge-offs within 12 months  \n",
       "11                      post charge off collection fee  \n",
       "12   Number of collections in 12 months excluding m...  \n",
       "13   The number of 30+ days past-due incidences of ...  \n",
       "14   The past-due amount owed for the accounts on w...  \n",
       "15           Loan description provided by the borrower  \n",
       "16   A ratio calculated using the borrower’s total ...  \n",
       "17   A ratio calculated using the co-borrowers' tot...  \n",
       "18   The month the borrower's earliest reported cre...  \n",
       "19   Employment length in years. Possible values ar...  \n",
       "20   The job title supplied by the Borrower when ap...  \n",
       "21   The upper boundary range the borrower’s FICO a...  \n",
       "22   The lower boundary range the borrower’s FICO a...  \n",
       "23   The total amount committed to that loan at tha...  \n",
       "24   The total amount committed by investors for th...  \n",
       "25                              LC assigned loan grade  \n",
       "26   The home ownership status provided by the borr...  \n",
       "27       A unique LC assigned ID for the loan listing.  \n",
       "28   Ratio of total current balance to high credit/...  \n",
       "29   The initial listing status of the loan. Possib...  \n",
       "..                                                 ...  \n",
       "123   Number of currently active installment trades...  \n",
       "124   Number of revolving accounts at time of appli...  \n",
       "125   Number of charge-offs within last 12 months a...  \n",
       "126   Number of collections within last 12 months e...  \n",
       "127   Months since most recent 90-day or worse rati...  \n",
       "128  Flags whether or not the borrower is on a hard...  \n",
       "129               Describes the hardship plan offering  \n",
       "130  Describes the reason the hardship plan was off...  \n",
       "131  Describes if the hardship plan is active, pend...  \n",
       "132  Amount of months that the borrower is expected...  \n",
       "133  The interest payment that the borrower has com...  \n",
       "134         The start date of the hardship plan period  \n",
       "135           The end date of the hardship plan period  \n",
       "136  The day the first hardship plan payment is due...  \n",
       "137  The number of months the borrower will make sm...  \n",
       "138  Account days past due as of the hardship plan ...  \n",
       "139     Loan Status as of the hardship plan start date  \n",
       "140  The original projected additional interest amo...  \n",
       "141  The payoff balance amount as of the hardship p...  \n",
       "142  The last payment amount as of the hardship pla...  \n",
       "143  The method by which the borrower receives thei...  \n",
       "144  Flags whether or not the borrower, who has cha...  \n",
       "145  The most recent date that the Debt_Settlement_...  \n",
       "146  The status of the borrower’s settlement plan. ...  \n",
       "147  The date that the borrower agrees to the settl...  \n",
       "148  The loan amount that the borrower has agreed t...  \n",
       "149  The settlement amount as a percentage of the p...  \n",
       "150  The number of months that the borrower will be...  \n",
       "151                                                NaN  \n",
       "152  * Employer Title replaces Employer Name for al...  \n",
       "\n",
       "[153 rows x 2 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns 151 & 152 are notes.  Let's remove them.\n",
    "excel_desc.drop(excel_desc.index[[151, 152]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fico_range_high',\n",
       " 'fico_range_low',\n",
       " 'id',\n",
       " 'last_fico_range_high',\n",
       " 'last_fico_range_low',\n",
       " 'revol_bal_joint ',\n",
       " 'sec_app_chargeoff_within_12_mths ',\n",
       " 'sec_app_collections_12_mths_ex_med ',\n",
       " 'sec_app_earliest_cr_line ',\n",
       " 'sec_app_fico_range_high ',\n",
       " 'sec_app_fico_range_low ',\n",
       " 'sec_app_inq_last_6mths ',\n",
       " 'sec_app_mort_acc ',\n",
       " 'sec_app_mths_since_last_major_derog ',\n",
       " 'sec_app_num_rev_accts ',\n",
       " 'sec_app_open_acc ',\n",
       " 'sec_app_revol_util ',\n",
       " 'total_rev_hi_lim \\xa0',\n",
       " 'verified_status_joint'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a set containing column names for both datasets\n",
    "excel_col_set = set(excel_desc.LoanStatNew)\n",
    "csv_col_set = set(df.columns)\n",
    "\n",
    "# indentify differences from the Excel & CSV files\n",
    "excel_col_set - csv_col_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that we are missing a total of 19 columns as described by the excel file.  We will continue on without these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Missing Data\n",
    "Reviewing the output from the .info() command, we can see that several columns have a severe amount of data missing.  We could take two routes here:\n",
    "\n",
    "1. We could impute the missing data.  The problem here is that when imputing large amounts of missing data we tend to introduce bias and decrease the overall variance.\n",
    "2. We could simply remove columns missing large amounts of data. \n",
    "\n",
    "I have selected to go with option 2 for data columns which are missing more than 10% of data.  As you can see below, some columns are missing over 10% of data.  Imputing this amount of data does not make sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_id: 100.00\n",
      "url: 100.00\n",
      "orig_projected_additional_accrued_interest: 99.71\n",
      "hardship_type: 99.68\n",
      "hardship_reason: 99.68\n",
      "hardship_status: 99.68\n",
      "deferral_term: 99.68\n",
      "hardship_amount: 99.68\n",
      "hardship_start_date: 99.68\n",
      "hardship_end_date: 99.68\n",
      "payment_plan_start_date: 99.68\n",
      "hardship_length: 99.68\n",
      "hardship_dpd: 99.68\n",
      "hardship_loan_status: 99.68\n",
      "hardship_payoff_balance_amount: 99.68\n",
      "hardship_last_payment_amount: 99.68\n",
      "debt_settlement_flag_date: 99.54\n",
      "settlement_status: 99.54\n",
      "settlement_date: 99.54\n",
      "settlement_amount: 99.54\n",
      "settlement_percentage: 99.54\n",
      "settlement_term: 99.54\n",
      "sec_app_mths_since_last_major_derog: 99.30\n",
      "sec_app_revol_util: 98.00\n",
      "revol_bal_joint: 97.98\n",
      "sec_app_earliest_cr_line: 97.98\n",
      "sec_app_inq_last_6mths: 97.98\n",
      "sec_app_mort_acc: 97.98\n",
      "sec_app_open_acc: 97.98\n",
      "sec_app_open_act_il: 97.98\n",
      "sec_app_num_rev_accts: 97.98\n",
      "sec_app_chargeoff_within_12_mths: 97.98\n",
      "sec_app_collections_12_mths_ex_med: 97.98\n",
      "dti_joint: 96.83\n",
      "annual_inc_joint: 96.83\n",
      "verification_status_joint: 96.83\n",
      "desc: 92.90\n",
      "mths_since_last_record: 82.79\n",
      "mths_since_recent_bc_dlq: 76.52\n",
      "mths_since_last_major_derog: 73.97\n",
      "mths_since_recent_revol_delinq: 66.77\n",
      "mths_since_last_delinq: 49.48\n",
      "il_util: 40.40\n",
      "next_pymnt_d: 36.01\n",
      "mths_since_rcnt_il: 33.11\n",
      "all_util: 31.21\n",
      "open_acc_6m: 31.21\n",
      "open_act_il: 31.21\n",
      "open_il_12m: 31.21\n",
      "open_il_24m: 31.21\n",
      "total_bal_il: 31.21\n",
      "open_rv_12m: 31.21\n",
      "open_rv_24m: 31.21\n",
      "max_bal_bc: 31.21\n",
      "inq_fi: 31.21\n",
      "total_cu_tl: 31.21\n",
      "inq_last_12m: 31.21\n",
      "mths_since_recent_inq: 16.19\n",
      "num_tl_120dpd_2m: 10.03\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# create a dictionary to hold the column name & missing data percentage\n",
    "cols = {}\n",
    "\n",
    "# loop through each column and find the percentage of missing data\n",
    "for c in df.columns:\n",
    "    cols[c] = df[c].isnull().sum() / len(df) * 100\n",
    "\n",
    "# Our missing data threshold is set to 10%\n",
    "data_threshold = 10\n",
    "del_cols = []\n",
    "\n",
    "# loop through columns and only keep those that are missing 10% of data\n",
    "for k, v in sorted(cols.items(), key=itemgetter(1), reverse=True):\n",
    "    if cols[k] > data_threshold:\n",
    "        print('{0}: {1:.2f}'.format(k, cols[k]))\n",
    "        del_cols.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop columns that are greater than 10%\n",
    "df.drop(del_cols, inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've removed a total of 59 columns due to missing data concerns.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Transformation & Feature Engineering\n",
    "Let's take a look at features that have mixed types that need to be reclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 term\n",
    "At the moment, term is represented by a string.  We want to cut the 'months' from the column to leave just a number of months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36 months    508969\n",
       "60 months    188556\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at values\n",
    "df.term.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we have NA values - let's drop these rows since it's only a very few rows.\n",
    "df = df.dropna(subset=['term'], axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to an integer\n",
    "df['term'] = [t[:2] for t in df.term]\n",
    "df['term'] = df.term.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 int_rate\n",
    "Interest rate currently has a percentage symbol - we want to remove this symbol and make it a float value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change interest rate from string to float\n",
    "int_rate_temp = [i[:-1] for i in df.int_rate]\n",
    "df['int_rate'] = pd.to_numeric(int_rate_temp, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 emp_length\n",
    "emp_length tracks the number of employment years for the given borrower.  It appears that employment years range from 0 to 10+ years.  We also have 'n/a', meaning the number of years of employment is not available. \n",
    "\n",
    "We will transform this data into an integer that represents the number of employment years\n",
    "* '0' represents less than 1 year of employment.  \n",
    "* '10' will represent 10 or more years of experience. \n",
    "* for the sake of this model, we will impute 'n/a' into the mean # of years for the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10+ years    231228\n",
       "2 years       63742\n",
       "< 1 year      59062\n",
       "3 years       56731\n",
       "1 year        46154\n",
       "5 years       43124\n",
       "4 years       42090\n",
       "6 years       31441\n",
       "8 years       28490\n",
       "7 years       27203\n",
       "9 years       25996\n",
       "Name: emp_length, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emp_length.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first replace the n/a with np.nan - this will allow us to convert the column from 'object' to 'int'\n",
    "df.emp_length.replace('n/a', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's transform this into a 0-10 range\n",
    "emp_length_fixed = []\n",
    "\n",
    "for length in df.emp_length:\n",
    "    if length == '< 1 year':\n",
    "        emp_length_fixed.append(0)\n",
    "    elif length == '1 year':\n",
    "        emp_length_fixed.append(1)\n",
    "    elif length == '2 years':\n",
    "        emp_length_fixed.append(2)\n",
    "    elif length == '3 years':\n",
    "        emp_length_fixed.append(3)\n",
    "    elif length == '4 years':\n",
    "        emp_length_fixed.append(4)\n",
    "    elif length == '5 years':\n",
    "        emp_length_fixed.append(5)\n",
    "    elif length == '6 years':\n",
    "        emp_length_fixed.append(6)\n",
    "    elif length == '7 years':\n",
    "        emp_length_fixed.append(7)\n",
    "    elif length == '8 years':\n",
    "        emp_length_fixed.append(8)\n",
    "    elif length == '9 years':\n",
    "        emp_length_fixed.append(9)\n",
    "    elif length == '10+ years':\n",
    "        emp_length_fixed.append(10)\n",
    "    else:\n",
    "        emp_length_fixed.append(length)\n",
    "\n",
    "df['emp_length'] = emp_length_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can now replace np.nan with the mean of the column\n",
    "df.emp_length.replace(np.nan, df.emp_length.mean(), inplace=True)\n",
    "\n",
    "# let's convert the column from a float into an integer\n",
    "df['emp_length'] = df.emp_length.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    231228\n",
       "5      85388\n",
       "2      63742\n",
       "0      59062\n",
       "3      56731\n",
       "1      46154\n",
       "4      42090\n",
       "6      31441\n",
       "8      28490\n",
       "7      27203\n",
       "9      25996\n",
       "Name: emp_length, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emp_length.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 emp_title\n",
    "The employment title contains a free form text.  It is hard to match title names as some have lower case, some have upper case, and others lie somewhere in between.  \n",
    "\n",
    "To fix this - we will convert the entire column to lower case. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     NaN\n",
       "1                                   Ryder\n",
       "2                                     NaN\n",
       "3                     AIR RESOURCES BOARD\n",
       "4                University Medical Group\n",
       "5                    Veolia Transportaton\n",
       "6               Southern Star Photography\n",
       "7                         MKC Accounting \n",
       "8                                     NaN\n",
       "9                               Starbucks\n",
       "10                  Southwest Rural metro\n",
       "11                                   UCLA\n",
       "12    Va. Dept of Conservation/Recreation\n",
       "13                                 Target\n",
       "14                                  SFMTA\n",
       "15               Internal revenue Service\n",
       "16                      Chin's Restaurant\n",
       "17                               Duracell\n",
       "18                  Connection Inspection\n",
       "19           Network Interpreting Service\n",
       "Name: emp_title, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets have a look at what type of data we are dealing with\n",
    "df.emp_title.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert titles to lowercase\n",
    "df['emp_title'] = [t.lower() if type(t) is str else t for t in df.emp_title]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at the value counts for each title - which employment titles are most popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new data frame with the title counts\n",
    "df_titles = df.emp_title.value_counts().to_frame()\n",
    "\n",
    "# rename columns\n",
    "df_titles.index.name = 'title'\n",
    "df_titles.columns = ['freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180719"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique titles do we have? \n",
    "len(df_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This an enormous amount of unique titles - let's cut this down by only focusing on job titles that occur 100 or more times.  Let's also produce a new column that contains the likelihood that each of these job titles will have a default loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at titles that occur more than 100 times\n",
    "df_titles = df_titles[df_titles.freq >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a filter that identifies loan status' which are 'bad'\n",
    "searchfor = ['Charged Off', \n",
    "             'Default', \n",
    "             'Does not meet the credit policy. Status:Charged Off', \n",
    "             'Late (16-30 days)', 'Late (31-120 days)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# create a new column that identifies how many bad loans each job title contains\n",
    "df_titles['default_percentage'] = [np.sum((df.emp_title==j) & (df.loan_status.str.contains('|'.join(searchfor)))) / df_titles.loc[j].freq for j in df_titles.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>default_percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>walmart</th>\n",
       "      <td>148</td>\n",
       "      <td>0.222973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ups</th>\n",
       "      <td>113</td>\n",
       "      <td>0.221239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at&amp;t</th>\n",
       "      <td>137</td>\n",
       "      <td>0.204380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ibm</th>\n",
       "      <td>100</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank of america</th>\n",
       "      <td>234</td>\n",
       "      <td>0.158120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us army</th>\n",
       "      <td>319</td>\n",
       "      <td>0.153605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usps</th>\n",
       "      <td>140</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wells fargo</th>\n",
       "      <td>111</td>\n",
       "      <td>0.144144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stocker</th>\n",
       "      <td>154</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team member</th>\n",
       "      <td>132</td>\n",
       "      <td>0.128788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dealer</th>\n",
       "      <td>193</td>\n",
       "      <td>0.124352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnc machinist</th>\n",
       "      <td>139</td>\n",
       "      <td>0.122302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phlebotomist</th>\n",
       "      <td>148</td>\n",
       "      <td>0.121622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cdl driver</th>\n",
       "      <td>116</td>\n",
       "      <td>0.120690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaiser permanente</th>\n",
       "      <td>126</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mail handler</th>\n",
       "      <td>121</td>\n",
       "      <td>0.115702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security guard</th>\n",
       "      <td>208</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>certified nursing assistant</th>\n",
       "      <td>142</td>\n",
       "      <td>0.112676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sous chef</th>\n",
       "      <td>151</td>\n",
       "      <td>0.112583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus operator</th>\n",
       "      <td>428</td>\n",
       "      <td>0.112150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>108</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table games dealer</th>\n",
       "      <td>155</td>\n",
       "      <td>0.109677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmacy tech</th>\n",
       "      <td>228</td>\n",
       "      <td>0.109649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correctional officer</th>\n",
       "      <td>119</td>\n",
       "      <td>0.109244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>press operator</th>\n",
       "      <td>121</td>\n",
       "      <td>0.107438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forman</th>\n",
       "      <td>252</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emt</th>\n",
       "      <td>140</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locomotive engineer</th>\n",
       "      <td>160</td>\n",
       "      <td>0.106250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech support</th>\n",
       "      <td>113</td>\n",
       "      <td>0.106195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parts manager</th>\n",
       "      <td>229</td>\n",
       "      <td>0.104803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vp</th>\n",
       "      <td>534</td>\n",
       "      <td>0.026217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operations specialist</th>\n",
       "      <td>116</td>\n",
       "      <td>0.025862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior financial analyst</th>\n",
       "      <td>156</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program specialist</th>\n",
       "      <td>156</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school psychologist</th>\n",
       "      <td>159</td>\n",
       "      <td>0.025157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>librarian</th>\n",
       "      <td>205</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associate attorney</th>\n",
       "      <td>125</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursing assistant</th>\n",
       "      <td>169</td>\n",
       "      <td>0.023669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maintenance manager</th>\n",
       "      <td>227</td>\n",
       "      <td>0.022026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product manager</th>\n",
       "      <td>426</td>\n",
       "      <td>0.021127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billing manager</th>\n",
       "      <td>151</td>\n",
       "      <td>0.019868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paralegal</th>\n",
       "      <td>101</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executive vice president</th>\n",
       "      <td>101</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior vice president</th>\n",
       "      <td>354</td>\n",
       "      <td>0.019774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mechanical engineer</th>\n",
       "      <td>204</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veterinarian</th>\n",
       "      <td>104</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facilities manager</th>\n",
       "      <td>163</td>\n",
       "      <td>0.018405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse practitioner</th>\n",
       "      <td>169</td>\n",
       "      <td>0.017751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>managing member</th>\n",
       "      <td>116</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales specialist</th>\n",
       "      <td>118</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpa</th>\n",
       "      <td>181</td>\n",
       "      <td>0.016575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shop foreman</th>\n",
       "      <td>183</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <td>619</td>\n",
       "      <td>0.016155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr generalist</th>\n",
       "      <td>124</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attorney</th>\n",
       "      <td>128</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payroll specialist</th>\n",
       "      <td>140</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psychologist</th>\n",
       "      <td>143</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chief financial officer</th>\n",
       "      <td>105</td>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer</th>\n",
       "      <td>112</td>\n",
       "      <td>0.008929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior pastor</th>\n",
       "      <td>126</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             freq  default_percentage\n",
       "title                                                \n",
       "walmart                       148            0.222973\n",
       "ups                           113            0.221239\n",
       "at&t                          137            0.204380\n",
       "ibm                           100            0.160000\n",
       "bank of america               234            0.158120\n",
       "us army                       319            0.153605\n",
       "usps                          140            0.150000\n",
       "wells fargo                   111            0.144144\n",
       "stocker                       154            0.136364\n",
       "team member                   132            0.128788\n",
       "dealer                        193            0.124352\n",
       "cnc machinist                 139            0.122302\n",
       "phlebotomist                  148            0.121622\n",
       "cdl driver                    116            0.120690\n",
       "kaiser permanente             126            0.119048\n",
       "mail handler                  121            0.115702\n",
       "security guard                208            0.115385\n",
       "certified nursing assistant   142            0.112676\n",
       "sous chef                     151            0.112583\n",
       "bus operator                  428            0.112150\n",
       "office                        108            0.111111\n",
       "table games dealer            155            0.109677\n",
       "pharmacy tech                 228            0.109649\n",
       "correctional officer          119            0.109244\n",
       "press operator                121            0.107438\n",
       "forman                        252            0.107143\n",
       "emt                           140            0.107143\n",
       "locomotive engineer           160            0.106250\n",
       "tech support                  113            0.106195\n",
       "parts manager                 229            0.104803\n",
       "...                           ...                 ...\n",
       "vp                            534            0.026217\n",
       "operations specialist         116            0.025862\n",
       "senior financial analyst      156            0.025641\n",
       "program specialist            156            0.025641\n",
       "school psychologist           159            0.025157\n",
       "librarian                     205            0.024390\n",
       "associate attorney            125            0.024000\n",
       "nursing assistant             169            0.023669\n",
       "maintenance manager           227            0.022026\n",
       "product manager               426            0.021127\n",
       "billing manager               151            0.019868\n",
       "paralegal                     101            0.019802\n",
       "executive vice president      101            0.019802\n",
       "senior vice president         354            0.019774\n",
       "mechanical engineer           204            0.019608\n",
       "veterinarian                  104            0.019231\n",
       "facilities manager            163            0.018405\n",
       "nurse practitioner            169            0.017751\n",
       "managing member               116            0.017241\n",
       "sales specialist              118            0.016949\n",
       "cpa                           181            0.016575\n",
       "shop foreman                  183            0.016393\n",
       "partner                       619            0.016155\n",
       "hr generalist                 124            0.016129\n",
       "attorney                      128            0.015625\n",
       "payroll specialist            140            0.014286\n",
       "psychologist                  143            0.013986\n",
       "chief financial officer       105            0.009524\n",
       "lawyer                        112            0.008929\n",
       "senior pastor                 126            0.007937\n",
       "\n",
       "[606 rows x 2 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What titles have the worse default percentage? \n",
    "df_titles.sort_values('default_percentage', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting to note that there appears to be a trend around employment titles that have bad default percentage.\n",
    "\n",
    "For example the following employment titles appear in several different forms, but all have poor default percentage.\n",
    "* US postal Service\n",
    "* Walmart\n",
    "* Target\n",
    "* Version \n",
    "\n",
    "In order to classify this data, we will create a new column named 'low_deliquences_jobs':\n",
    "* 1 identifies frequent employment titles having less than 5% default percentage\n",
    "* 0 identifies all other employmen titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_deliquences_jobs = df_titles[df_titles.default_percentage < 0.05].index\n",
    "\n",
    "df['low_deliquent_job'] = [1 if j in low_deliquences_jobs else 0 for j in df.emp_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we've created a new column for our job titles that perform well - let's now drop the emp_title column\n",
    "df.drop('emp_title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 revol_util\n",
    "revol_util relates to the amount of credit the borrower is usuing relative to all available revolving credit.  This can be used as a key indicator for bad loans. At the moment, it contains a percentage symbol - which needs to be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, get rid of any missing values\n",
    "df = df.dropna(subset=['revol_util'], axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['revol_util'] = [e[:-1] for e in df.revol_util]\n",
    "df['revol_util'] = df.revol_util.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 earliest_cr_line\n",
    "\n",
    "earliest_cr_line relates to month/year in which the borrow first opened a credit line.  \n",
    "\n",
    "we can create a new feature here to capture the length in which a borrower has had credit - before dropping the original field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sep-2003    4923\n",
       "Sep-2004    4829\n",
       "Aug-2003    4725\n",
       "Oct-2003    4630\n",
       "Sep-2002    4601\n",
       "Name: earliest_cr_line, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.earliest_cr_line.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to a date field\n",
    "df['earliest_cr_line'] = pd.to_datetime(df.earliest_cr_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the length of credit line in months\n",
    "df['credit_line_length_mnths'] = (pd.to_datetime('today') - df.earliest_cr_line) / np.timedelta64(1, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop column\n",
    "df.drop('earliest_cr_line', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 loan status\n",
    "We have several loan statuses - but we want to convert the status into a binary non-default/default representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid\n",
      "Charged Off\n",
      "Does not meet the credit policy. Status:Fully Paid\n",
      "Does not meet the credit policy. Status:Charged Off\n",
      "Current\n",
      "Late (16-30 days)\n",
      "Late (31-120 days)\n",
      "In Grace Period\n",
      "Default\n",
      "Issued\n"
     ]
    }
   ],
   "source": [
    "for s in df.loan_status.unique():\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group status into good vs bad status\n",
    "good = [\n",
    "    'Current',\n",
    "    'Fully Paid',\n",
    "    'Issued',\n",
    "    'Does not meet the credit policy. Status:Fully Paid'\n",
    "    'In Grace Period'\n",
    "]\n",
    "                    \n",
    "bad = [\n",
    "    'Charged Off',\n",
    "    'Default',\n",
    "    'Does not meet the credit policy. Status:Charged Off',\n",
    "    'Late (16-30 days)',\n",
    "    'Late (31-120 days)',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert into a new column\n",
    "df['is_bad'] = [1 if s in bad else 0 for s in df.loan_status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>is_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Charged Off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loan_status  is_bad\n",
       "0    Fully Paid       0\n",
       "1   Charged Off       1\n",
       "2    Fully Paid       0\n",
       "3    Fully Paid       0\n",
       "4    Fully Paid       0\n",
       "5    Fully Paid       0\n",
       "6    Fully Paid       0\n",
       "7    Fully Paid       0\n",
       "8   Charged Off       1\n",
       "9   Charged Off       1\n",
       "10   Fully Paid       0\n",
       "11   Fully Paid       0\n",
       "12  Charged Off       1\n",
       "13   Fully Paid       0\n",
       "14  Charged Off       1"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['loan_status', 'is_bad']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 inq_last_6mnths\n",
    "The column related to credit inquires in the last 6 months denotes whether this borrower has requested a credit check in the last 6 months.  A value here can identify that the borrower has attempted to get additional credit before requesting this loan - which could identify that they are stuggling to get a loan based on prior activities. \n",
    "\n",
    "We are going to catogrize this column to simply identify whether or not they have requested a credit check. \n",
    "\n",
    "Based on the data - we see that the data is heavily skewed with the majority of borrowers having 0 or 1 credit checks.  Credit checks are required for various neccessities in life (e.g. renting an apartment), we will say less that 2 credit checks is classified as 'no'.  Everything 2 and above we will consider as 'yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     418802\n",
       "1.0     183175\n",
       "2.0      63164\n",
       "3.0      21921\n",
       "4.0       6597\n",
       "5.0       2407\n",
       "6.0        490\n",
       "7.0        181\n",
       "8.0        115\n",
       "9.0         50\n",
       "10.0        24\n",
       "11.0        15\n",
       "12.0        15\n",
       "15.0         9\n",
       "14.0         6\n",
       "13.0         6\n",
       "18.0         4\n",
       "16.0         3\n",
       "17.0         2\n",
       "19.0         2\n",
       "24.0         2\n",
       "31.0         1\n",
       "32.0         1\n",
       "25.0         1\n",
       "28.0         1\n",
       "20.0         1\n",
       "33.0         1\n",
       "27.0         1\n",
       "Name: inq_last_6mths, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.inq_last_6mths.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['inq_last_6mths_cat'] = [1 if c <= 2 else 0 for c in df.inq_last_6mths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    665141\n",
       "0     31856\n",
       "Name: inq_last_6mths_cat, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.inq_last_6mths_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's remove the inq_last_6mths column\n",
    "df.drop('inq_last_6mths', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 pub_rec\n",
    "pub_rec represents the number of derogatory public records for the borrower.  Similiarly to inquiries of credit checks in the last 6 months, the data is heavily skewed with the majority of data falling in 0 derogatory records.  We will categorize this value as well to simply identify whether or not the borrower 'has' or 'has not' had a derogatory public record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     578234\n",
       "1.0      97845\n",
       "2.0      13499\n",
       "3.0       4220\n",
       "4.0       1607\n",
       "5.0        747\n",
       "6.0        384\n",
       "7.0        173\n",
       "8.0         95\n",
       "9.0         54\n",
       "10.0        41\n",
       "11.0        33\n",
       "12.0        17\n",
       "13.0        10\n",
       "14.0         6\n",
       "15.0         5\n",
       "19.0         5\n",
       "16.0         5\n",
       "17.0         3\n",
       "28.0         3\n",
       "20.0         2\n",
       "31.0         1\n",
       "18.0         1\n",
       "49.0         1\n",
       "47.0         1\n",
       "46.0         1\n",
       "21.0         1\n",
       "23.0         1\n",
       "26.0         1\n",
       "24.0         1\n",
       "Name: pub_rec, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pub_rec.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['pub_rec_cat'] = [1 if p > 0 else 0 for p in df.pub_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    578234\n",
       "1    118763\n",
       "Name: pub_rec_cat, dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pub_rec_cat.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's remove the pub_rec column\n",
    "df.drop('pub_rec', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 funded_amnt\n",
    "funded_amnt represents how much money the borrower receives.  This could be less than the requested loan amount, which might identify that a borrower is not trustworthy on repayment.  We will create a new category to indentify loans which are not fully funded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new column for fully_funded\n",
    "df['fully_funded'] = [1 if x == 0 else 0 for x in df.loan_amnt - df.funded_amnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    694997\n",
       "0      2000\n",
       "Name: fully_funded, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fully_funded.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10 Categorical Datatypes\n",
    "We have several 'object' type columns, some of which we will keep and convert into categorical datatypes, and others that we will drop.  Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grade', 'sub_grade', 'home_ownership', 'verification_status',\n",
       "       'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code',\n",
       "       'addr_state', 'initial_list_status', 'last_pymnt_d',\n",
       "       'last_credit_pull_d', 'application_type', 'hardship_flag',\n",
       "       'disbursement_method', 'debt_settlement_flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the number of columns which are of type 'object'\n",
    "df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a mixture of categorical and date columns in the above list.  We will only focus on categorical datatypes in this section.  I've separated out the columns into two groupings:\n",
    "* cat_cols_keep\n",
    "* cat_cols_drop\n",
    "\n",
    "These two groupings are processed in the subsections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols_keep = ['grade',\n",
    "            'sub_grade', \n",
    "            'home_ownership', \n",
    "            'verification_status',\n",
    "            'loan_status',\n",
    "            'purpose',\n",
    "            'addr_state',\n",
    "            'initial_list_status',\n",
    "            'zip_code',\n",
    "            'hardship_flag',\n",
    "            'application_type']\n",
    "\n",
    "cat_cols_drop = ['title',\n",
    "                 'pymnt_plan',\n",
    "                 'disbursement_method',\n",
    "                 'debt_settlement_flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.1 Categorical Columns - Keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert each column to type 'category'\n",
    "for col in cat_cols_keep:\n",
    "    df[col] = pd.Categorical(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 696997 entries, 0 to 65498\n",
      "Data columns (total 87 columns):\n",
      "loan_amnt                     696997 non-null float64\n",
      "funded_amnt                   696997 non-null float64\n",
      "funded_amnt_inv               696997 non-null float64\n",
      "term                          696997 non-null int64\n",
      "int_rate                      696997 non-null float64\n",
      "installment                   696997 non-null float64\n",
      "grade                         696997 non-null category\n",
      "sub_grade                     696997 non-null category\n",
      "emp_length                    696997 non-null int64\n",
      "home_ownership                696997 non-null category\n",
      "annual_inc                    696997 non-null float64\n",
      "verification_status           696997 non-null category\n",
      "issue_d                       696997 non-null object\n",
      "loan_status                   696997 non-null category\n",
      "pymnt_plan                    696997 non-null object\n",
      "purpose                       696997 non-null category\n",
      "title                         683603 non-null object\n",
      "zip_code                      696997 non-null category\n",
      "addr_state                    696997 non-null category\n",
      "dti                           696758 non-null float64\n",
      "delinq_2yrs                   696997 non-null float64\n",
      "open_acc                      696997 non-null float64\n",
      "revol_bal                     696997 non-null float64\n",
      "revol_util                    696997 non-null float64\n",
      "total_acc                     696997 non-null float64\n",
      "initial_list_status           696997 non-null category\n",
      "out_prncp                     696997 non-null float64\n",
      "out_prncp_inv                 696997 non-null float64\n",
      "total_pymnt                   696997 non-null float64\n",
      "total_pymnt_inv               696997 non-null float64\n",
      "total_rec_prncp               696997 non-null float64\n",
      "total_rec_int                 696997 non-null float64\n",
      "total_rec_late_fee            696997 non-null float64\n",
      "recoveries                    696997 non-null float64\n",
      "collection_recovery_fee       696997 non-null float64\n",
      "last_pymnt_d                  689694 non-null object\n",
      "last_pymnt_amnt               696997 non-null float64\n",
      "last_credit_pull_d            696956 non-null object\n",
      "collections_12_mths_ex_med    696884 non-null float64\n",
      "policy_code                   696997 non-null float64\n",
      "application_type              696997 non-null category\n",
      "acc_now_delinq                696997 non-null float64\n",
      "tot_coll_amt                  654552 non-null float64\n",
      "tot_cur_bal                   654552 non-null float64\n",
      "total_rev_hi_lim              654552 non-null float64\n",
      "acc_open_past_24mths          654552 non-null float64\n",
      "avg_cur_bal                   654552 non-null float64\n",
      "bc_open_to_buy                647653 non-null float64\n",
      "bc_util                       647387 non-null float64\n",
      "chargeoff_within_12_mths      696884 non-null float64\n",
      "delinq_amnt                   696997 non-null float64\n",
      "mo_sin_old_il_acct            635814 non-null float64\n",
      "mo_sin_old_rev_tl_op          654552 non-null float64\n",
      "mo_sin_rcnt_rev_tl_op         654552 non-null float64\n",
      "mo_sin_rcnt_tl                654552 non-null float64\n",
      "mort_acc                      654552 non-null float64\n",
      "mths_since_recent_bc          648073 non-null float64\n",
      "num_accts_ever_120_pd         654552 non-null float64\n",
      "num_actv_bc_tl                654552 non-null float64\n",
      "num_actv_rev_tl               654552 non-null float64\n",
      "num_bc_sats                   654552 non-null float64\n",
      "num_bc_tl                     654552 non-null float64\n",
      "num_il_tl                     654552 non-null float64\n",
      "num_op_rev_tl                 654552 non-null float64\n",
      "num_rev_accts                 654552 non-null float64\n",
      "num_rev_tl_bal_gt_0           654552 non-null float64\n",
      "num_sats                      654552 non-null float64\n",
      "num_tl_30dpd                  654552 non-null float64\n",
      "num_tl_90g_dpd_24m            654552 non-null float64\n",
      "num_tl_op_past_12m            654552 non-null float64\n",
      "pct_tl_nvr_dlq                654399 non-null float64\n",
      "percent_bc_gt_75              647562 non-null float64\n",
      "pub_rec_bankruptcies          695664 non-null float64\n",
      "tax_liens                     696922 non-null float64\n",
      "tot_hi_cred_lim               654552 non-null float64\n",
      "total_bal_ex_mort             654552 non-null float64\n",
      "total_bc_limit                654552 non-null float64\n",
      "total_il_high_credit_limit    654552 non-null float64\n",
      "hardship_flag                 696997 non-null category\n",
      "disbursement_method           696997 non-null object\n",
      "debt_settlement_flag          696997 non-null object\n",
      "low_deliquent_job             696997 non-null int64\n",
      "credit_line_length_mnths      696997 non-null float64\n",
      "is_bad                        696997 non-null int64\n",
      "inq_last_6mths_cat            696997 non-null int64\n",
      "pub_rec_cat                   696997 non-null int64\n",
      "fully_funded                  696997 non-null int64\n",
      "dtypes: category(11), float64(62), int64(7), object(7)\n",
      "memory usage: 437.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# validate that columns are now of type category\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10.2 Categorical Columns - Drop\n",
    "I've decided to drop several categorical columns after reviewing the data and determined that they are not of value for this specific analysis.  I've addressed the contents of each column below, prior to dropping the columns from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt consolidation         339156\n",
       "Credit card refinancing    125378\n",
       "Home improvement            42532\n",
       "Other                       38602\n",
       "Major purchase              13876\n",
       "Medical expenses             7813\n",
       "Debt Consolidation           6467\n",
       "Business                     6447\n",
       "Car financing                6405\n",
       "Vacation                     4726\n",
       "Moving and relocation        4398\n",
       "Home buying                  2676\n",
       "Consolidation                2293\n",
       "Debt Consolidation Loan      2236\n",
       "debt consolidation           1959\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title is a free form text supplied by the borrower, representing the reason why the borrower wants the\n",
    "# loan.  The information contained within this column is summarized clearly within the 'purpose' column\n",
    "# We will drop the title column, and keep the purpose column for classification\n",
    "df.title.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    695467\n",
       "y      1530\n",
       "Name: pymnt_plan, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pymnt_plan has an extremely small variance within the data - thus we will drop it\n",
    "df.pymnt_plan.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021903127975424308"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the variance of the pymnt_plan column - notice how small it is\n",
    "np.var(df.pymnt_plan.map({'y':1, 'n':0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cash         695301\n",
       "DirectPay      1696\n",
       "Name: disbursement_method, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disbursement_method has an extremely small variance within the data - thus we will drop it\n",
    "df.disbursement_method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024273750533246752"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the variance of disbursement_method\n",
    "np.var(df.disbursement_method.map({'Cash':1, 'DirectPay':0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    693805\n",
       "Y      3192\n",
       "Name: debt_settlement_flag, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debt_settlement_flag has an extremely small variance within the data - thus we will drop it\n",
    "df.debt_settlement_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004558673520581696"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the variance of debt_settlement - notice how small it is\n",
    "np.var(df.debt_settlement_flag.map({'Y':1, 'N':0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove the above columns as they do not serve any purpose for our model\n",
    "df.drop(cat_cols_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.11 date columns\n",
    "Similarily to categorical columns, we have several 'object' type columns that can be converted to date datatypes, and other columns that we will drop. Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['issue_d', 'last_pymnt_d', 'last_credit_pull_d'], dtype='object')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the number of columns which are of type 'object'\n",
    "df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only focus on date datatypes in this section.  I've separated out the columns into two groupings:\n",
    "* date_cols_keep\n",
    "* date_cols_drop\n",
    "\n",
    "These two groupings are processed in the subsections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_cols_keep = ['issue_d']\n",
    "\n",
    "date_cols_drop = ['last_pymnt_d',\n",
    "                 'last_credit_pull_d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 date columns - keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert each column to date\n",
    "for col in date_cols_keep:\n",
    "    df[col] = pd.to_datetime(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create 2 new columns from the issue date field to indentify the month & year the loan was issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new columns\n",
    "df['issue_d_month'] = df.issue_d.dt.month\n",
    "df['issue_d_year'] = df.issue_d.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 date columns - drop\n",
    "I've decided to drop several date columns after reviewing the data and determined that they are not of value for this specific analysis.  I've addressed the contents of each column below, prior to dropping the columns from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_pymnt_d relates to repayment - I do not see any use for this at this time.  If a loan is late, \n",
    "# the loan status will represent this \n",
    "df.last_pymnt_d.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# relates to the last time a credit report was pulled - I do not see any use for this at this time\n",
    "df.last_credit_pull_d.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df.drop(date_cols_drop,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Explore Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "# create histogram of loan amounts\n",
    "df.loan_amnt.hist(bins=7, edgecolor='lightblue')\n",
    "\n",
    "# setup titles\n",
    "plt.title('Loans')\n",
    "plt.xlabel('Loan Amount ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# setup labels\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "fig.savefig('../reports/figures/loan_amnt_hist.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's see the statistics for these loans\n",
    "df.loan_amnt.plot(kind='box')\n",
    "\n",
    "# setup titles\n",
    "plt.ylabel('Loan Amount ($)')\n",
    "\n",
    "# setup labels\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loan_amnt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that loans within the 7,500 - 20,000 range are most popular. Let's look at loans by status - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what do we look like for loan amounts per grade? I've removed the 'sharey' attribute since many\n",
    "# of the status' have very few values compared to the overall frequency\n",
    "\n",
    "status = df.loan_status.unique()\n",
    "\n",
    "fig, axs = plt.subplots(len(status), sharex=True,figsize=(10,19))\n",
    "\n",
    "# create bins\n",
    "bins = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "\n",
    "# create a colormap to represent each loan status\n",
    "cm = plt.cm.rainbow\n",
    "colors = cm(np.linspace(0, 1, len(status)))\n",
    "\n",
    "for i, l in enumerate(status):\n",
    "    line = axs[i].hist(df[df.loan_status==l].loan_amnt, bins=bins, color=colors[i], label=l)\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set labels\n",
    "axs[0].set_title('Loan Frequency by Status')\n",
    "plt.xlabel('Loan Amount ($)')\n",
    "fig.text(0., 0.5, 'Frequency', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "fig.savefig('../reports/figures/loan_amnt_hist_by_status.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what percentages does each loan status represent? \n",
    "dic = {}\n",
    "for s in status:\n",
    "    dic[s] = format(len(df[df.loan_status==s]) / len(df), '.3f')\n",
    "\n",
    "for (status, per) in sorted(dic.items(), key= lambda x: x[1], reverse=True):\n",
    "    print('{}: {}'.format(status, per))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "Nothing too extrodainary here in the loan amounts.  We see:\n",
    "* About 90% of loans are in the Current/Fully Paid statuses, meaning we are generally doing well with loans overall!\n",
    "* Loans range from $500 - $40,000, with the average loan being $14,755.\n",
    "* Loans in a chraged off/default/grace period/late status tend to have a higher mean than those in a current/fully "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Explore Default vs Non-Default Loans\n",
    "Do bad loans appear more frequently in higher loan amounts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# can we say anything about loan amounts being related to whether they are good or bad? \n",
    "df.groupby('is_bad').loan_amnt.plot.hist(bins=7)\n",
    "\n",
    "# update titles\n",
    "plt.title('Default vs Non-Default Loans')\n",
    "plt.xlabel('Loan Amount ($)')\n",
    "\n",
    "# setup labels\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "# create legend\n",
    "leg_legend = ['Non-Default', 'Default']\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, leg_legend)\n",
    "\n",
    "fig.savefig('../reports/figures/loan_amnt_hist_defaultvsnondefault.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "* The majority of loans appear to be non-default.\n",
    "* Percentage wise, we don't see any significance trends between the loan amounts & default status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Explore Issue Date\n",
    "Are there any trends in the loans over time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# group by date, and summarize by loan ammount, then plot\n",
    "df.groupby('issue_d').loan_amnt.sum().plot.area(figsize=(15,10))\n",
    "\n",
    "# set labels\n",
    "plt.title('Loans Issued by Date')\n",
    "plt.ylabel('Amount ($)')\n",
    "plt.xlabel('Date Issued')\n",
    "\n",
    "# get current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# disable scientific notation on the y axis\n",
    "ax.ticklabel_format(axis='y', style='plain')\n",
    "\n",
    "# format values with comma\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "fig.savefig('../reports/figures/loan_amnt_by_date.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -- For future reference --\n",
    "# You need to specify axis if you want it to apply to only x or y\n",
    "#\n",
    "# disable scientific notation\n",
    "## ax.ticklabel_format(style='plain')\n",
    "#\n",
    "# disable offset notation\n",
    "## ax.ticklabel_format(useOffset=False)\n",
    "#\n",
    "# disable both offset & scientific\n",
    "## ax.ticklabel_format(useOffset=False, style='plain')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we see spikes in this graphs - is there some seasonality to loans? \n",
    "\n",
    "# grab figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create plot\n",
    "df.groupby('issue_d_month').loan_amnt.count().plot.bar(color='b',figsize=(10,8), width=1, edgecolor='lightblue')\n",
    "\n",
    "# set labels\n",
    "plt.title('Number of Loans Issued By Month')\n",
    "plt.ylabel('# of Loans')\n",
    "plt.xlabel('Month Issued')\n",
    "\n",
    "# get current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# format values with comma\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "# format x axis\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "plt.xticks(range(len(months)), months, rotation='vertical')\n",
    "\n",
    "fig.savefig('../reports/figures/loan_count_by_month.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "* Since it's inception, Lending Club has increased it's loan capcity considerably.\n",
    "* There appears to be a trend of loans being issued at the ending of each quarter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Explore Terms\n",
    "Do terms have any diret correlation to bad loans? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create histogram\n",
    "df.groupby(['term', 'is_bad']).loan_amnt.count().unstack().plot.bar(figsize=(8,7),stacked=True, width=1, edgecolor='lightgrey')\n",
    "\n",
    "# update titles\n",
    "plt.title('Default vs Non-Default Loans by Term')\n",
    "plt.ylabel('Loan Amount ($)')\n",
    "plt.xlabel('Term (Months)')\n",
    "\n",
    "# setup labels\n",
    "ax = plt.gca()\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "# create legend\n",
    "leg_legend = ['Non-Default', 'Default']\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, leg_legend)\n",
    "plt.xticks(rotation='horizontal')\n",
    "\n",
    "plt.savefig('../reports/figures/terms_defaultvsnondefault.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what do we look like for loan amounts per term? \n",
    "\n",
    "term = df.term.unique()\n",
    "\n",
    "fig, axs = plt.subplots(len(term), sharex=True,sharey=True,figsize=(10,7))\n",
    "\n",
    "# create a colormap to represent each loan status\n",
    "cm = plt.cm.rainbow\n",
    "colors = cm(np.linspace(0, 1, len(term)))\n",
    "\n",
    "bins = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "\n",
    "for i in range(len(term)):\n",
    "    line = axs[i].hist(df[df.term==term[i]].loan_amnt, bins=bins, color=colors[i], label=str(term[i])+' months')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set labels\n",
    "axs[0].set_title('Loan Frequency by Term')\n",
    "plt.xlabel('Loan Amount ($)')\n",
    "fig.text(0., 0.5, 'Frequency', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "fig.savefig('../reports/figures/loan_amnt_hist_by_term.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "* Majority of loans are 36 months\n",
    "* Term lenght does not appear to have an impact the default status\n",
    "* It appear that larger loan sizes are more likely to have a 60 month term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Explore Grade\n",
    "How do loan grades impact loan amounts & status? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find number of grades\n",
    "grades = df.grade.unique()\n",
    "\n",
    "# create a colormap to represent each grade\n",
    "cm = plt.cm.rainbow\n",
    "colors = cm(np.linspace(0, 1, len(grades)))\n",
    "\n",
    "# create plot\n",
    "df.groupby(['issue_d', 'grade']).loan_amnt.sum().unstack().plot.area(figsize=(15,10), color=colors)\n",
    "\n",
    "# set labels\n",
    "plt.title('Loans Issued by Date & Grade')\n",
    "plt.ylabel('Amount ($)')\n",
    "plt.xlabel('Date Issued (Month/Year)')\n",
    "\n",
    "# get current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# disable scientific notation on the y axis\n",
    "ax.ticklabel_format(axis='y', style='plain')\n",
    "\n",
    "# format values with comma\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.savefig('../reports/figures/loan_amnt_by_date_grade.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what does this look like percentage wise?\n",
    "for group, data in df.groupby(['grade']).is_bad:\n",
    "    print('Grade: {0} Bad({1:.2f}) Good({2:.2f})'.format(group, np.sum(data==1)/len(data), np.sum(data==0)/len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what do we look like for loan amounts per grade? \n",
    "\n",
    "fig, axs = plt.subplots(7, sharex=True, sharey=True, figsize=(10,19))\n",
    "\n",
    "bins = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000]\n",
    "\n",
    "for i, g in enumerate(sorted(grades)):\n",
    "    line = axs[i].hist(df[df.grade==g].loan_amnt, bins=bins, color=colors[i], label=g)\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set labels\n",
    "axs[0].set_title('Loan Frequency by Grade')\n",
    "plt.xlabel('Loan Amount ($)')\n",
    "fig.text(0., 0.5, 'Frequency', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "plt.savefig('../reports/figures/loan_amnt_by_grade.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "* Lending club has diversified their loan grades over the years\n",
    "* The lower the grade, the more likley a loan will default - Grade G(25%) vs Grade A(3%)\n",
    "* Loans of grade B & C appear to be most frequent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Explore Interest Rates\n",
    "How do interest rates impact loan amounts and deafult status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup bins\n",
    "bins = np.arange(0, 35, 2.5)\n",
    "\n",
    "# create the histogram\n",
    "df.int_rate.plot.hist(bins=bins, edgecolor='lightgrey')\n",
    "\n",
    "# set titles\n",
    "plt.xlabel('Interest Rates (%)')\n",
    "\n",
    "# setup labels\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:,.1f}'))\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.savefig('../reports/figures/int_rate_hist.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what do we look like for loan amounts per grade? \n",
    "fig, axs = plt.subplots(len(grades), sharey=True, figsize=(11,18))\n",
    "\n",
    "for i, g in enumerate(sorted(grades)):\n",
    "    line = axs[i].hist(df[df.grade==g].int_rate, bins=bins, color=colors[i], label=g, edgecolor='lightblue')\n",
    "    plt.xlabel('Interest Rate (%)')\n",
    "    axs[i].legend()\n",
    "\n",
    "# Set labels\n",
    "axs[0].set_title('Interest Frequency by Grade')\n",
    "fig.text(0., 0.5, 'Frequency', ha='center', va='center', rotation='vertical')\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.savefig('../reports/figures/int_rate_hist_by_grade.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.int_rate.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "* Interest percentage is tightly correlated with grade - as grade decreases, interest increases \n",
    "* The mean interest rate falls within the 12.5 - 15% range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.7 Explore Home Ownership\n",
    "How does home ownership play into the number of loans? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create graph\n",
    "df.home_ownership.value_counts().plot(kind='barh', figsize=(7, 7), width=1, edgecolor='lightblue')\n",
    "\n",
    "# set labels\n",
    "plt.xlabel('# of loans')\n",
    "plt.ylabel('Ownership Type')\n",
    "\n",
    "# get current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# format y label ticks\n",
    "ax.xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.home_ownership.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "* We see that home ownership of 'mortgage, rent, own' make up the majority of loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Explore Purpose\n",
    "What are the reasons for the loans being issues? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create graph\n",
    "df.purpose.value_counts().plot(kind='bar', color='b',figsize=(10, 7), width=1, edgecolor='lightblue')\n",
    "\n",
    "# set labels\n",
    "plt.xlabel('Loan Purpose')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# get current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# format y label ticks\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "\n",
    "plt.savefig('../reports/figures/loan_purpose_hist.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do we know what types of loans have the best chance of being repaid? \n",
    "\n",
    "loans = []\n",
    "\n",
    "for p in df.purpose.unique():\n",
    "    good = np.sum([(df.purpose==p) & (df.is_bad==0)]) / np.sum(df.purpose==p)\n",
    "    bad = np.sum([(df.purpose==p) & (df.is_bad==1)]) / np.sum(df.purpose==p)\n",
    "\n",
    "    loans.append([p, good, bad])\n",
    "\n",
    "loans = pd.DataFrame(loans)\n",
    "loans.columns = ['Purpose', 'Non-default', 'Default']\n",
    "loans.set_index('Purpose', inplace=True)\n",
    "loans.sort_values('Non-default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "* Majority of loans are for paying debt consoildation\n",
    "* Loans for the purpose of credit card, car, home imporovements have the best chances for repayment\n",
    "* Loans for educational purposes have the worst repayment perecentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Explore By State\n",
    "Where are the majority of loans being issued?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "import json\n",
    "import os\n",
    "\n",
    "# create dataframe for loan amount grouped by state\n",
    "df_amnt_by_state = df[['addr_state', 'loan_amnt']].groupby('addr_state').sum().reset_index()\n",
    "\n",
    "# scale amounts by 10's of millions\n",
    "dic_amnt_by_state = df_amnt_by_state.set_index('addr_state').loan_amnt / 10000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import branca.colormap as cm\n",
    "\n",
    "# create a color scale\n",
    "linear = cm.linear.OrRd.to_step(8).scale(\n",
    "    dic_amnt_by_state.min(), \n",
    "    dic_amnt_by_state.max())\n",
    "\n",
    "linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the map\n",
    "m = folium.Map(location=[48, -102], zoom_start=4)\n",
    "\n",
    "# load the geojson of the US states\n",
    "geo_json_data = json.load(open('../data/external/us_states.json'))\n",
    "\n",
    "# add the geojson to the map\n",
    "folium.GeoJson(\n",
    "    geo_json_data,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': linear(dic_amnt_by_state.loc[feature['id']]),\n",
    "        'color': 'black',\n",
    "        'weight': 1,\n",
    "        'fillOpacity': 0.8}\n",
    ").add_to(m)\n",
    "\n",
    "# add the scale\n",
    "linear.caption = 'Loan Amounts (100s of Millions)'\n",
    "m.add_child(linear)\n",
    "\n",
    "# show the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "* largest number of loans are provided in California, new york, texas & florida "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Null Values\n",
    "\n",
    "Before moving on, we need to address missing values within our dataset.  Digging into some of the missing data, we find that a handful of columns were missing in the dataset prior to 2012 - as a result, we see all loans prior to 2012 having null data for these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at dates for the given records missing values\n",
    "df[df.num_bc_sats.isnull()]['issue_d'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I'd rater not drop 5 years worth of data.  As a result, we will try to fill NA values \n",
    "# with the means for each column\n",
    "\n",
    "# identify the column names introduce after 2012\n",
    "missing_data_impute_mean = ['tot_coll_amt',\n",
    "                'tot_cur_bal',\n",
    "                'total_rev_hi_lim',\n",
    "                'acc_open_past_24mths',\n",
    "                'avg_cur_bal',\n",
    "                'mo_sin_old_rev_tl_op',\n",
    "                'mo_sin_rcnt_rev_tl_op',\n",
    "                'mo_sin_rcnt_tl',\n",
    "                'mort_acc',\n",
    "                'num_accts_ever_120_pd',\n",
    "                'num_actv_bc_tl',\n",
    "                'num_actv_rev_tl',\n",
    "                'num_bc_sats',\n",
    "                'num_bc_tl',\n",
    "                'num_il_tl',\n",
    "                'num_op_rev_tl',\n",
    "                'num_rev_accts',\n",
    "                'num_rev_tl_bal_gt_0',\n",
    "                'num_sats',\n",
    "                'num_tl_30dpd',\n",
    "                'num_tl_90g_dpd_24m',\n",
    "                'num_tl_op_past_12m',\n",
    "                'tot_hi_cred_lim',\n",
    "                'total_bal_ex_mort',\n",
    "                'total_bc_limit',\n",
    "                'total_il_high_credit_limit']\n",
    "\n",
    "# impute the mean\n",
    "for c in missing_data_impute_mean:\n",
    "    df[c] = df[c].fillna(value=int(df[c].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have another handful of column missing 7-8% of data.  Instead of imputing the mean within these column, we are\n",
    "# simply going to drop the columns as to not introduce bias and reduce variance. \n",
    "missing_data_drop_cols = ['bc_open_to_buy',\n",
    "                'bc_util', \n",
    "                'mo_sin_old_il_acct',\n",
    "                'mths_since_recent_bc',\n",
    "                'pct_tl_nvr_dlq',\n",
    "                'percent_bc_gt_75']\n",
    "\n",
    "for c in missing_data_drop_cols:\n",
    "    print('{}: {}'.format(c, np.sum(df[c].isnull()) / len(df[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop missing columns\n",
    "df = df.drop(missing_data_drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we have another few columns missing 0-1% of data.  Instead of imputing the data within these columns, I will \n",
    "# simply drop the rows having NA present\n",
    "\n",
    "missing_data_drop_rows = ['dti',\n",
    "                'collections_12_mths_ex_med',\n",
    "                'chargeoff_within_12_mths',\n",
    "                'pub_rec_bankruptcies',\n",
    "                'tax_liens']\n",
    "\n",
    "# show calculation of missing data\n",
    "for c in missing_cols:\n",
    "    print('{}: {}'.format(c, np.sum(df[c].isnull()) / len(df[c])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop rows having missing data\n",
    "df = df.dropna(subset=missing_data_drop_rows, axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Correlation\n",
    "Let's see how our variables are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=.9)\n",
    "fig, ax = plt.subplots(figsize=(16,16))         # Sample figsize in inches\n",
    "sns.heatmap(df.corr(), cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Summary**\n",
    "\n",
    "We see some correlation between 'is_bad' and -\n",
    "* int_rate\n",
    "* out_princp\n",
    "* out_princp_inv\n",
    "* total_rec_princp\n",
    "* total_rec_late_fee\n",
    "* recoveries\n",
    "* collection_recovery_fee\n",
    "* last_pymnt_amnt\n",
    "* issue_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following columns have been determined to bring little to no value to our model and will be removed:\n",
    "\n",
    "* issue_d\n",
    "    * This is a date feature, which cannot be used in classification.\n",
    "\n",
    "* policy_code (1)\n",
    "    * The same value (1) occurs for every record.\n",
    "\n",
    "* zip_code\n",
    "    * We are going to utlize the state for this analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Delete columns\n",
    "del_cols = ['issue_d',\n",
    "            'policy_code',\n",
    "            'zip_code']\n",
    "\n",
    "df.drop(del_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Export\n",
    "Let's export our dataframe to a CSV so that we have a fresh dataset to begin out model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df.to_csv('./../data/processed/LCdata_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
